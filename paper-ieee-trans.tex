\documentclass[journal]{IEEEtran}
\usepackage{graphicx}
\usepackage{array}
\usepackage{subfigure}
\usepackage{adjustbox}

\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % \DeclareGraphicsExtensions{.eps}
\fi

%\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Delivering Reliable Software in the European Scientific Arena: Evolution of Methodologies and New Trend Analysis}
%\title{15 years of European scientific software development: evolution and methodologies}

\author{E. Ronchieri,
        P. Orviz Fernandez,
        M. David,
	D. C. Duma,
        J. Gomes,
        D. Salomoni
\thanks{D. C. Duma, E. Ronchieri, and D. Salomoni are with INFN - CNAF, Bologna, Italy.}
\thanks{P. Orviz Fernandez, is with CSIC, Santander, Spain.}
\thanks{M. David, and J. Gomes are with LIP, Lisbon, Portugal.}%
}

% The paper headers
%\markboth{IEEEtran for IEEE Journals}

\maketitle

\begin{abstract}
From the advent of Grid technology -- as the new paradigm of distributed
computing -- to the current days of Cloud computing models, the continuous need
of new tools and services to match the scientific community requirements has been
addressed in Europe by various projects dedicated to software development
and e-Infrastructure creation, operation and management.
% the creation of software development and e-Infrastructure coordination dedicated projects.
This work examines the evolution of the software engineering methodologies used in past and
present European Commission-funded projects to illustrate how the research on software
reliability has progressed in Europe over the last 15 years following the foundation of the
first project in 2001. In particular, we will summarize the techniques and procedures
applied to deliver quality software, highlighting the main challenges and barriers confronted
at the time, and how they were partially or totally overcome. The knowledge base established
throughout the years, sustained by the advances in the area of software engineering,
definitely conformed a significant breakthrough in the reliability of software delivered in the
European research arena. Recent software development projects funded by the European
Commission are good evidences of such insights, where the enforcement of Quality Assurance
procedures is present since the very early stages of the software development process.
\end{abstract}

\begin{IEEEkeywords}
Software Reliability, Quality Assurance, Software Metrics, Software Testing
Techniques, DevOps
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}

\IEEEPARstart{D}uring the last 15 years the provision of an European e-Infrastructure,
supporting an unified access to large-scale computing and intense data analysis
applications, has been driven by the needs of scientific communities as part of their
pan-European research collaborations. One such example is the Worldwide
Large Hadron Collider (LHC) Computing Grid infrastructure, driven
by the particle physics scientific community, built to satisfy the computing needs
of processing, storing and analysis of the very large amount of data produced by the
LHC particle accelerator. A significant number of innovation projects and
technology transfer activities -- from the European Union's funded 5th, 6th and 7th Framework Programmes,
and recently from the Horizon 2020 programme \cite{h2020} -- have as their main goal to
develop software solutions that provide a seamless and transparent access to distributed
computing and data resources by the researchers.

Major developments were achieved throughout the years focused on providing new
functionalities, partially neglecting the adoption of software engineering methodologies, in the early days.
The released software was less tested, resulting in a high rate of
rollbacks and patches applied to production systems. Thereby, the stability and
reliability of the e-Infrastructures was often compromised, affecting
negatively their exploitation by the scientific communities.

Soon it became apparent the need for a better balance between the addition of new features
and the reliability of the released software. Consequently, a substantial part of the
software lifecycle would have to be devoted to the improvement of the quality of the software being
delivered. At this point, evolving software engineering practices were
considered and gradually adopted to define and implement quality procedures, the organization of development teams
and deployment of pilot testbeds.

Analysing the European Commission (EC)-funded software projects over the last decade,
one can observe a continuous increase in the prominence and robustness of software
testing and validation procedures. The
evolution of the software engineering methodologies (creation of the Agile
Manifesto \cite{agile-manifesto}, and rise of DevOps practices \cite{zhu}) together
with the parallel advancements in the information and communication technology
field (such as virtualization, the enabling technology for Cloud computing and
operating--system--level virtualization known as containerization) definitely motivated this trend. All of which
complemented by the emergence of automation and event-response tools.

In this paper, we outline a set of EC-funded projects
ranging from 2001 to nowadays, in which the authors were involved.
For each project, the challenges, the methodologies and
the achievements towards software reliability are described.

The reminder of this paper is
organized as follows. Section \ref{sec:ev} details the evolution of research on
software reliability in EC-projects. Section \ref{sec:ntsr} provides
information about new research trends in software reliability based upon the
experiences from the recent {\sl INDIGO--DataCloud} project. Conclusions are drawn in Section \ref{sec:con}.

\section{Evolution of research on software reliability in EC-projects}
\label{sec:ev}

The EC projects considered in this paper are listed chronologically in Table
\ref{tab:eup}. Each project paved the way of the subsequent projects,
following a logic evolution in which the role of the quality and reliability of the software have
consistently increased. As shown in Table \ref{tab:feat}, the most recent projects are more committed to and aware of software reliability practices.
Table \ref{tab:feat} also shows the topics addressed in the following sections, highlighting
the commonalities and specific features on software reliability.

\begin{table}[!h]
%% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{List of EC-projects}
\label{tab:eup}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{p{1.6cm}p{1.5cm}p{3cm}l}
\hline
\hline
\\
Logo & Short Name & Long Name & Duration\\
\hline
\hline
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/datagrid}
\end{minipage}
    & DataGrid &
Research and Technological Development for an International Data Grid & 2001--2003\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/egee}
\end{minipage}
     & EGEE I, II, III &
Enabling Grids for E-sciencE & 2004--2010\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/etics}
\end{minipage}
     & ETICS 1, 2 &
E--Infrastructure for Testing, Integration and Configuration of Software & 2006-2010\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/emi}
\end{minipage}
     & EMI &
Europeean Middleware Initiative & 2010--2013\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/egi-inspire}
\end{minipage}
     & EGI-Inspire &
Integrated Sustainable Pan-European Infrastructure for Researchers in Europe
 & 2010--2014\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/egi_engage}
\end{minipage}
     & EGI Engage &
Engaging the EGI Community towards an Open Science Commons
 & 2015--2017\\
\begin{minipage}{.3\textwidth}
\includegraphics[width=15mm,height=7.5mm]{images/indigo}
\end{minipage}
     & INDIGO--DataCloud &
INtegrating Distributed data Infrastructures for Global ExplOitation
 & 2015--2017\\
\hline
\hline
\end{tabular}
\end{table}

\subsection{DataGrid}

The {\sl DataGrid} \cite{cordis:datagrid} project (Jan 2001 -- Dec 2003)
main goal was to provide scientific communities, including physics, biology and
earth sciences, with intensive computing and large-scale dataset analysis capabilities.
The project brought together 21 academic and industry partners, from 15 different countries \cite{gagliardi}.
Grid was the emerging technology to be used in order to address their requirements,
thus the project delivered its own software distribution, named EDG (EU {\sl DataGrid}), strongly
based on Globus middleware components and services \cite{globus}. The project was organized in 12 work packages, from
which 5 were devoted to software development and coordinated by an
Architecture Task Force, supervising the overall design and technical consistency
of the developments.

Without previous experience in such widely
collaborative projects, a big effort was spent in devising solutions for several
challenges \cite{datagrid}, namely the 1) communication overhead, as a
result of the large geographical separation of the involved parties in the
development tasks, 2) the fast evolution of the requirements from the user
communities (50 use cases from the three scientific area), and 3) the lack of a body
of knowledge for academic software engineering.

The Agile manifesto \cite{agile-manifesto} was by then an emerging methodology, not yet
considered by the project, and as such the project's
development design suffered from the lack of the methods, tools, techniques and best
practices emerging from these new discipline of software engineering
\cite{agile}. Nevertheless, the project focused on the experiences and procedures
used by diverse collaborative open source software projects, such as Linux and Apache, trying to
achieve a higher maturity level \cite{cmm}.

\begin{table}[!h]
%% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Features on software reliability in EC-projects}
\label{tab:feat}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{adjustbox}{max width=0.5\textwidth}
\begin{tabular}{llllllll}
\hline
\hline
Feature & DataGrid & EGEEs & ETICSs & EMI & EGIs & INDIGO--DC\\
\hline
\hline
Architecture Task Force&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
Communication Handling&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
Requirements Handling&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
Agile Methodologies&&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
Source code inspection&&&&$\surd$&&$\surd$\\
Build/Testing Management Procedure&$\surd$&$\surd$&$\surd$&$\surd$&&$\surd$\\
Software Product Metrics&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
Quality Criteria Definition&&&$\surd$&$\surd$&$\surd$&$\surd$\\
%Manual Certification Procedure&$\surd$&$\surd$&&$\surd$&&\\
Automatic Certification&&&$\surd$&&$\surd$&$\surd$\\
Auto-generated Documentation&&$\surd$&$\surd$&$\surd$&$\surd$&$\surd$\\
DevOps practices adoption (CI, CD)&&&&&&$\surd$\\
\hline
\hline
\end{tabular}
\end{adjustbox}
\end{table}

\subsection{Enabling Grids for E--sciencE}

The three phases of Enabling Grids for E--sciencE ({\sl EGEE}, Apr 2004 -- Apr 2010)
\cite{cordis:egee, cordis:egee2, cordis:egee3} projects brought together
scientists and engineers from over 240 institutions in 45 countries aiming to
provide a seamless Grid infrastructure for e--Science. {\sl EGEE--II} and {\sl EGEE--III}
featured the internationalization (outside Europe) of the project, embracing worldwide research
institutions and user communities. The software to sustain the increasing
requirements coming from the diverse scientific communities would need to develop a
rich set of new services while maintaining a sustainable infrastructure for
Grid computing, eventually used by more than 15 thousand researchers and deployed in
over 250 institutions.

The {\sl gLite} middleware \cite{glite} was the
official software distribution of {\sl EGEE} as of 2006, after two years of prototyping and
re--engineering efforts to converge with the {\sl LHC} Computing Grid (LCG--2), Virtual
Data Toolkit (VDT) and Condor \cite{condor} software stacks. The
development team was comprised of more that 80 people from 12 academic and
industrial partners, which issued more than 10 thousand bugs fixes, 1.7 thousand patches and
defined over 300 development tasks tracked using bug/task management tools.

The source code was available at a private, centralized version control system.
The code passed through a manual certification procedure at the time of the release.
This procedure aimed to improve the reliability of the software components by applying
acceptance criteria checks at each stage of the software development lifecycle
\cite{egee:acceptance-criteria} i.e. integration, certification, pre--production and
production. Starting with {\sl EGEE--II}, the project adopted automation in the software
lifecycle process by leveraging the automatic build system for Grid middleware, that is
the {\sl ETICS} \cite{etics} solution.

\subsection{E--Infrastructure for Testing, Integration and Configuration of Software}

The E--Infrastructure for Testing, Integration and Configuration of Software
\cite{cordis:etics, cordis:etics2} ({\sl ETICS}, Jan 2006 -- Feb 2010) project aimed
at addressing the challenges in producing quality software in distributed,
collaborative projects such as {\sl EGEE} and its {\sl gLite} middleware. The framework
integrated different technologies and tools in order to provide automated configuration,
build and testing capabilities, as well as auto-generated documentation and
software metrics gathering such as Source Lines Of Code (SLOC), complexity and
number of defects/bugs \cite{etics}. The {\sl ETICS} framework was the first automated
service for delivering quality software products in distributed environments like
the Grids.



\subsection{European Middleware Initiative}

The European Middleware Initiative ({\sl EMI}, May 2010 -- Apr 2013)
\cite{cordis:emi} project joined the 4 major Grid middleware providers in
Europe at the time -- {\sl gLite}, {\sl UNICORE}, {\sl ARC} and {\sl dCache} --
with the goal to maintain and evolve the middleware focusing on extending their
interoperability and improving the reliability of the services. The
ISO/IEC 9126 \cite{iso-9126} standard was used in order to identify a set of
characteristics that needed to be present in the {\sl EMI} software products and
processes to be able to meet the {\sl EMI} quality requirements
\cite{emi-quality-model}.

For each software characteristic, a set of associated
metrics and Key Performance Indicators (KPIs) were identified and defined in
detail in the {\sl EMI} Metrics Specification \cite{emi-metrics}. The project
leveraged the {\sl ETICS} service for the development, continuous integration and release management,
as well as for metric tracking, making queries on the collected data to display
them through the chart generation framework.

\subsection{EGI--Integrated Sustainable Pan--European Infrastructure}

The {\sl EGI--InSPIRE} (Integrated Sustainable Pan--European Infrastructure for
Researchers in Europe, May 2010 -- May 2014) project \cite{cordis:egi-inspire}
was the continuation of the {\sl EGEE--III} project, with the objective of establishing and
maintaining a sustainable European Grid Infrastructure, composed by a federation of National
Grid Initiatives and interoperable with other Grids worldwide.
This goal would had been accomplished through the
development and maintenance of some operational tools, such as the Operations Portal \cite{egi-ops},
the {\sl EGI} Helpdesk \cite{ggus}, or the Grid configuration database (GOCDB) \cite{gocdb}, and the
management of the software provisioning process \cite{mario}, dealing with the validation and distribution of the software to
the production infrastructures. As a result, this process led to a production--ready
Grid computing middleware distribution named {\sl UMD} (Unified Middleware Distribution). At that time the {\sl UMD}
was a stack of about 250 software components from several technology providers such
as {\sl EMI} and {\sl Globus}. In order to be distributed through UMD
repositories, the software had to be compliant with EGI's Quality Criteria (QC) \cite{egi-qc}. The
QC defined a set of requirements in different areas: documentation, deployment, security, information
model and operations.
{\sl UMD} is still being used and
deployed in the European scientific e--Infrastructures under the follow--up
project {\sl EGI--Engage} (Engaging the EGI Community towards an Open Science
Commons) \cite{cordis:egi-engage}. This distribution is currently complemented
by a Cloud--specific one called {\sl CMD} (Cloud Middleware Distribution).

\subsection{INtegrating Distributed data Infrastructures for Global
explOitation}

The {\sl INDIGO--DataCloud} (INtegrating Distributed data Infrastructures for Global
explOitation, Apr 2015 -- Sep 2017) \cite{cordis:indigo} is the last
project of software development considered in this paper. At the time of writing
this paper, the project is succeeding in providing solutions to address the existing gaps in
Cloud Platform--as--a--Service (PaaS) and Software--as--a--Service (SaaS) levels,
helping developers, e--Infrastructures administrators and scientific communities to exploit
Cloud computing benefits.

\section{New trends in software reliability}
\label{sec:ntsr}

{\sl INDIGO--DataCloud} is the most recent project included in this paper and thus
leveraged the lessons learned from the previous experiences described in
Section \ref{sec:ev}. The expertise gathered throughout these years was highly
profitable in terms of the evaluation and application of innovative software engineering
methodologies, the management of new technologies to put those methodologies
into practice, and the compilation and analysis of the appropriate set of metrics to measure the
quality of the solutions implemented. All the above with the additional complexity of being framed into a
large collaborative project with an extensive list of partners.

In the following sections, we will describe the three main pillars that sustain the project's strategy to attain reliability throughout the
software lifecycle. A solid \textit{Software Quality Assurance (SQA) criteria
and metrics gathering definition}, will provide guidelines to develop quality
software, validating each change in the code, and facilitating its adoption. The software lifecycle is continuously monitored
by a set of metrics, allowing promptly reactions to detected malfunctions throughout the
process. A \textit{bottom-up adoption of DevOps principles} will promote automation to enable
the foregoing change-based development process and set up advanced delivery mechanisms.
The last key pillar is the \textit{two-factor validation} carried out over the project's pilot testbeds and
e-Infrastructure resource provider's early-adoption.


%The {\sl INDIGO--DataCloud} project reflects the progress made in software
%quality and reliability aspects throughout the past scientific European
%experiences. Nevertheless (I would remove this), the project???s Quality Assurance procedures are also
%highly influenced by the insights of current big worldwide collaborations of
%software development. These collaborations have continuously inspired the use of new
%technologies and procedures to increase the robustness and quality of the
%software being delivered. In this scenario, the implementation of the DevOps culture
%is one of the major outcomes, as this paradigm has been progressively adopted by the
%project.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{images/codestyle.png}
\caption{Code style standards followed by {\sl INDIGO--DataCloud}'s software products.}
\label{fig:fig_codestyle}
\end{figure}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{images/unittest.png}
\caption{Comparison of the unit testing coverage values for the {\sl INDIGO--DataCloud} software stack over the {\sl INDIGO--1} and {\sl INDIGO--2} major releases.}
\label{fig:fig_unittest}
\end{figure*}

\begin{figure}[ht]
\centering
\includegraphics[width=0.45\textwidth, height=50mm]{images/confman.png}
\caption{Trend line showing the adoption of Configuration Management tools throughout the project lifetime.}
\label{fig:fig_confman}
\end{figure}

\subsection{Software Quality Procedures}
\label{subsec:sqa}

The initial software quality policies were defined in the first deliverable document of the
project \cite{indigo-d31}. The policies where reviewed periodically taking into account the requirements
from the user communities, the feedback from the development teams and the insights of software engineering practices. These policies cover the 1) identification
and description of the \emph{SQA requirements} that the produced software need
to comply with, and the 2) \emph{quality metrics}, to monitor each software product's
behaviour throughout the development, release and post--release stages.

\subsubsection{SQA criteria}

The SQA criteria is a set of conventions and recommendations that pave the way for
the adequate development, timely deliver and reliable operation of the produced software components.
It emphasizes the quality requirements and best practices to be applied at the
development phase, such as style and testing compliance or human code reviews, to protect the
production source code versions. Furthermore, there are provided the minimum requirements on documentation content and it is stresed the importance of the usage of automated
solutions for software deployment.

\begin{itemize}
\item \textit{Code style}.
The ultimate goal for code style assessment is to improve the readability and reusability of the source code produced under the scope of the
project. Code style standards are enforced for every software component in the project stack. Community
most-adopted or \textit{de-facto standards} are initially recommended, however the development teams eventually
choose the set of guidelines to comply with.  Figure \ref{fig:fig_codestyle} highlights the code style standards and their popularity
in the {\sl INDIGO--DataCloud} software stack.

\item \textit{Unit and Functional testing}.
Changes involving the addition of new functionalities, are required to be tested. \textit{Regression
testing} in this context is accomplished by enforcing the definition, and periodic execution, of tests for the fixed issues that ensure these issues are not reintroduced during the development activities.
 \textit{Unit testing} completes the source code testing evaluation by
focusing on the code's internal design. The SQA criteria sets a recommended threshold of
70\% coverage for unit testing. In Figure \ref{fig:fig_unittest}, unit testing coverage is compared
for each software component between the two major {\sl INDIGO--DataCloud} releases, denoting an incremental
trend over the course of the project. It can be seen that 50\% of the components were over the
70\% threshold while slightly less than 80\% of the product stack had values over 50\% coverage.

\item \textit{Integration testing}. Software components usually interact with other services during
operation. Integration testing deals with the interactions among coupled software components or
parts of a system that cooperate to achieve a given functionality. This type of testing might be
complex and, based on the project's experience, difficult to be implemented in an automatic way. The aim is to
guarantee the overall operation of the component with regard to the services it interfaces with,
whenever new functionalities are introduced.

\item \textit{Code review}.
Represents the last step in the change management pipeline, once the candidate change has
successfully passed through the testing methods described previously. It implies the human-based
revision of the proposed change to discuss its adequacy in terms of scope, objective fulfilment,
documentation completeness, etc. On approval, the candidate change is definitely merged into
the source code's production version. Human code reviewing is paramount in the software quality assessment, specially
important when the SQA testing requirements are fully automated. Secure code reviews are also 
done at this stage, assessing common vulnerabilities from inputs coming from automated linters
and manual dynamic application security testing.

\item \textit{Documentation}.
The SQA criteria sets the path for the adoption of the developed software by
defining the documentation content, according to the target audience. This requirement also
promotes the automation, both in terms of documentation creation and service deployment. The
\textit{documentation is treated as code}, using a markup language, automatically rendered and
uploaded to online repositories \cite{indigo-gitbook}. Thus documentation is portable and
human--reviewed, using the same workflow as the code does, validating the changes before being
updated into the production repository.

\item \textit{Automated Deployment}.
To lower the barriers of software adoption, the SQA criteria requires the automated
deployment of the products delivered as part of the catalogue. Automation in this context is
tackled using a configuration management tool. These tools allow to have an
\textit{Infrastructure as Code} (IaC), managing the component's deployment through declarative
definitions. The definition files appear as additional source of documentation
-- self-documenting code -- as they sequentially guide the component's deployment process in multiple
platforms. {\sl INDIGO--DataCloud} project contributed to open--source IaC tools such
as Ansible \cite{indigo-ansible} and Puppet \cite{indigo-puppet}. A representative example of
such contribution are the \textit{50 roles} being developed from scratch, currently hosted in
the Ansible Galaxy portal \cite{indigo-galaxy}. Figure
\ref{fig:fig_confman} shows the number of products that offer an automated means for deployment.
It shows an increase after the {\sl INDIGO--1} release and in the previous weeks of each
of the two major releases.
\end{itemize}

\subsubsection{Quality metrics}

The evaluation of the software quality is performed by measuring the values of
the metrics and Key Performance Indicators (KPIs) defined based upon the
ISO/IEC 9126 standard. These metrics cover the development, release and
maintenance phases of the software lifecycle.

\textit{Development metrics} are obtained programatically from several sources, namely GitHub
API and Jenkins service, and graphically displayed as GitHub pages using GrimoireLab
framework \cite{grimoirelab}. Per-component weekly reports, including the SQA requirement
fulfilment, are issued and individually discussed through the different communication channels
with the development teams. Issue tracking metrics and KPIs are an essential piece of information
of both feature addition and defect solving, useful to detect and fix misbehaviours while in the
development phase.

\textit{Release metric} sources are the online repository servers, namely the
Linux packages \cite{indigo-pkg-repo} and DockerHub \cite{indigo-dockerhub} repositories. Jenkins
server also contains valuable release data as it is the service where the packages
and containers are being built before being uploaded to the online repositories. Release
KPIs primarily focus on the frequency and efficiency -- mainly rollbacks -- statistics.

\textit{Maintenance and user support metrics} are key for continuously improving the response
to issues reported by external users. Feedback is collected from outside helpdesks, such as
EGI's GGUS \cite{ggus}, and the GitHub Issues tracker.

\subsection{DevOps practices}
\label{sec:devops}

The DevOps methods emphasize the SQA techniques to avoid infrastructure
disruption whenever new developments are deployed into production systems. The
following DevOps approaches have been progressively adopted throughout the project's
lifetime, being one of its major outcomes in terms of software reliability.

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth, height=50mm]{images/jenkins_CI_builds.png}
\caption{Evolution of the total number of testing builds triggered automatically as part of the Jenkins CI implementation.}
\label{fig:fig_jenkins_CI_builds}
\end{figure}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{images/devops.png}
\caption{Continuous Delivery workflow for Docker images.}
\label{fig:fig_CD}
\end{figure*}


\subsubsection{Continuous Integration (CI)}
\label{subsec:ci}
The {\sl INDIGO--DataCloud} project promoted the application of a CI scenario that enforces,
for any piece of produced software, the testing requirements defined in the SQA criteria,
as described in Section \ref{subsec:sqa}. Such environment requires an automation
ready--to--go infrastructure where the different services and technologies involved interact with each
other to trigger the source code validation pipeline for each candidate change. The
pipeline is mainly comprised by the code style validation, unit and functional testing
coverage. The CI pipeline is complemented with additional quality checks, such as
integration tests for the software components where automation of this type of testing
is applicable, or security linters for the code static analysis of suspicious
constructs that could lead to security risks. Metrics gathering also takes part of
the CI pipeline to have a per-change trend evolution of the common source code
related metrics, such as SLOC or the cyclomatic complexity.

The practical implementation of the CI scenario leveraged on tightly integrated open
source tools such as GitHub \cite{github} -- as the online source code repository --,
Jenkins \cite{jenkins} -- the event-response CI system -- and Docker container
provisioning to provide instant computing power needed for executing the pipeline jobs.
The project defined a source code contribution workflow, based on GitHub Pull Requests
(PRs), where each change automatically triggers in Jenkins the associated quality and
metric tracking checks on PR creation or update. The set of required checks contained
in the CI pipeline, report their exit status back to GitHub preventing the change to be
approved if they are not successfully executed. As each change is validated, the chances
of early detection of defects increases. Within this scenario, the cost of defect solving
is dramatically reduced and the reliability of the software solutions improved, as any
bug or design issue is likely to be detected and subsequently corrected in this phase.

Figure \ref{fig:fig_jenkins_CI_builds} shows the evolution, throughout the
{\sl INDIGO--DataCloud}'s first and second releases, of the required test types builds since the
implementation of the CI infrastructure. Automated functional testing coverage were not
available for all the software stack, thus the associated number of builds are fewer.

\subsubsection{Continuous Delivery}
As DevOps suggests, frequent releases positively affect the reliability of the software as
they involve fewer changes and usually more correlated. The software updates of
{\sl INDIGO--DataCloud} products, taking place since the second major release, are passing through
a Continuous Delivery (CD) pipeline that adds the packaging of the software right after the
successful execution of the CI pipeline previously described. Consequently, CI-validated
software components are automatically delivered in online repositories without the need of
any human interaction but ultimately requiring expert supervision to validate the results.

{\sl INDIGO--DataCloud} software stack is delivered in form of Linux software packages (rpms, debs)
and Docker containers. The CD approach is different for each type of software packaging. \textit{Linux
package pipeline} intentionally delivers the packages produced in a pre-production -- preview --
branch. Before that, once the software packages have been created, they are uploaded to a
testing branch. The available automated deployment solution -- see \cite{subsec:sqa} -- checks
the installation and configuration of the component relying on the testing repository. On
successful completion, the packages are then automatically signed and subsequently moved to
the preview branch, from where they finally be made available in the production branch after
the release manager supervises the process.

The \textit{Docker container pipeline} uses instead the automated deployment solution to
actually install and configure the software component in the container image. Once this is
done the recently created image is uploaded to the production DockerHub repository, tagged
with the label corresponding to the current {\sl INDIGO--DataCloud} release. Figure
\ref{fig:fig_CD} shows the complete workflow of the Docker container CD implementation,
automatically triggered by a change in the source code.

\begin{figure*}
	\centering
	\begin{subfigure}
		\centering
\includegraphics[width=0.85\textwidth]{images/disvis-flow.png}
\caption{DevOps pipeline to distribute Docker images for Disvis application.}
\label{fig:fig_disvis}
	\end{subfigure}
	\quad
	\begin{subfigure}
		\centering
\includegraphics[width=\textwidth]{images/pilotpreview.png}
\caption{Resource centers supporting the Pilot Preview testbed and corresponding
set of deployed {\sl INDIGO--DataCloud} components or services.}
\label{fig:fig_pilotpreview}
	\end{subfigure}
\end{figure*}


\subsubsection{DevOps adoption from user communities}

The experience gathered throughout the project regarding the adoption of
different DevOps practices is not only useful and suitable for the software related
to the core services in the {\sl INDIGO--DataCloud} solution, but also applicable to the
development and distribution of the applications coming from the user communities.

Two applications from "Definition of Support to Research Communities" work package,
DisVis \cite{disvis} and PowerFit \cite{powerfit}, were
integrated into a similar CI/CD pipeline described in section \ref{sec:devops}.
Figure \ref{fig:fig_disvis} shows the pipeline for the Disvis application.

User application developers were provided with both a means to validate the
source code before merging and the creation of a new versioned Docker image,
automatically available in the {\sl INDIGO--DataCloud}???s application repository.

The novelty introduced in the pipeline above is the validation of the application.
Once the application is packaged as a Docker image, and subsequently uploaded
to the Dockerhub repository, it is instantiated in a new container to be validated.
The application is then executed and the results compared with a set of reference outputs.
This pipeline implementation goes a step forward by testing the application
execution for the latest available Docker image in the catalogue.


\subsection{Integration, preview and early adoption}

Two pilot infrastructures are at the disposal of developers and scientific
communities involved in the project. The aim of these testbeds is to test the
level of integration between the components involved in the {\sl INDIGO--DataCloud}
solutions and use cases validation, by deploying and executing the applications
with the last stable version of the software in environments as similar as
possible to production ones. A map of the Pilot Preview
infrastructure is depicted in Figure \ref{fig:fig_pilotpreview}, it shows the
resources providers and the components or services they deployed and supported.

The released software is tested in production environments through the
Staged--Rollout process, before its inclusion in the EGI's Cloud Middleware Distribution (CMD).
Selected resource providers are requested to install
the most updated stable versions of the software, and to give access to them to their users. The
Staged--Rollout process is key to detect and mitigate issues that could only
appear in production environments.

\section{Conclusion}
\label{sec:con}

After more that a decade of experiences collected throughout the reviewed
EU-funded software development and e-Infrastructure management projects, it
becomes apparent that the European software produced for scientific purposes is
evolving to a more sustainable model where the quality and reliability of
software is being prioritized. The gradual adoption of software engineering insights, such as
DevOps practices or Agile methodologies, are leading the change. In this regard, the continuous evolution of the open--source
collaborative tools, extending their capabilities to bring along tight
integrations amongst other services, matched the requirements of such practices
and procedures, facilitating in a great manner their implementation in real scenarios.

Reliability of the software has been substantially improved by applying the SQA
criteria in the development stage. Consequently, each change in the source code
that is meant to be integrated in the production version, is validated according
to the SQA testing requirements. Thus, defects are detected and corrected early in the
software lifecycle, reducing the cost of fixing errors at later stages. Automation is
key in this process, allowing the implementation of a CI scenario that enforces
the SQA criteria compliance. The application of more advanced DevOps practices
resulted in the implementation of CD pipelines to extend automation to the
delivery of packages. Thereby, safe and frequent software releases are doable, reducing
the impact on production systems. In this regard, a pre-production validation,
through the preview testbeds or resource centers early adoption -- handled by the
Staged--rollout process --, alleviates the likelihood of discovering uncovered
issues at production.

Software lifecycle demands as well from a continuous measurement and analysis
process that permits timely reactions to discover and fix defects throughout the
development, release and post-release or maintenance stages. Conscientious metric
tracking and response sits at the core of an appropriate software maturity, as
ultimate reliability can only be achieved by enforcing and empowering the SQA
criteria through each stage of the software lifecycle.

\section*{Acknowledgment}

{\sl INDIGO--DataCloud} project has received funding from the European Research
Council (ERC) under the European Union's Horizon 2020 research and innovation
programme (grant agreement n?? 777536).

\begin{thebibliography}{1}

\bibitem{h2020}
\emph{HORIZON 2020}, The EU Framework Programme for Research and Innovation [Online]. Available: https://ec.europa.eu/programmes/horizon2020/

\bibitem{agile-manifesto}
\emph{Manifesto for Agile Software Development} [Online]. Available: http://agilemanifesto.org

\bibitem{zhu}
L. Zhu and L. Bass and G. Champlin-Scharff, \emph{DevOps and Its Practices},
IEEE Software, vol. 33, no. 3, pp. 32--34, May-June 2016.

\bibitem{cordis:datagrid}
\emph{DataGrid project}, European Community Research and Development
Information Service (CORDIS) [Online]. Available: http://cordis.europa.eu/project/rcn/53665\_en.html

\bibitem{gagliardi}
Gagliardi F., Jones B., Reale M., Burke S., \emph{European DataGrid Project: Experiences of Deploying a Large Scale Testbed for E-science Applications},
in Calzarossa M.C., Tucci S. (eds) Performance Evaluation of Complex Systems: Techniques and Tools, Lecture Notes in Computer Science, vol 2459. Springer, 2002.

\bibitem{globus}
I. Foster and C. Kesselman, \emph{Globus: a Metacomputing Infrastructure
Toolkit}, International Journal of Supercomputer Applications, vol. 11, no. 2,
pp. 115???128, 1997.

\bibitem{datagrid}
L. Momtahan and A. Martin, \emph{e-Science Experiences: Software Engineering
Practice and the EU DataGrid}, in Proc. Asia-Pacific Software Engineering
Conference, Gold Coast, Queensland, Australia, pp. 269-275, IEEE Press,
4-6 Dec. 2002.

\bibitem{agile}
T. Dingsoyr, \emph{A decade of agile methodologies: Towards explaining agile
software development} in The Journal of Systems and Software, Elsevier Inc,
2012.

\bibitem{cmm}
Paulk et al., \emph{Capability maturity model for software}, Software
Engineering Institute, report CMU/SEI-93-TR-24, ESC-TR-93-177, Feb. 1993.

\bibitem{cordis:egee}
\emph{Enabling Grids for E-sciencE (EGEE)} project, European Community
Research and Development Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/80149\_en.html

\bibitem{cordis:egee2}
\emph{Enabling Grids for E-sciencE-II (EGEE-II)} project, European Community
Research and Development Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/99189\_en.html

\bibitem{cordis:egee3}
\emph{Enabling Grids for E-sciencE-III (EGEE-III)} project, European Community
Research and Development Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/87264\_en.html

\bibitem{egee:acceptance-criteria}
\emph{Definition and Documentation of the Revised Software Life-Cycle Process},
Milestone MSA3.4.2, 2010, EGEE-III project [Online]. Available: https://edms.cern.ch/ui/file/1062487/2/EGEE-III-MSA3.4.2-1062487-v1\_4.pdf

\bibitem{glite}
E. Laure et al, \emph{Programming the Grid with gLite}, in Jin, H., Reed, D.A.,
Jiang, W. (eds.) Computational Methods in Science and Technology, vol. 12(1),
pp. 33???45, Scientific Publishers OWN, 2006.

\bibitem{condor}
D. Thain, T. Tannenbaum, M. Livny, \emph{Condor and the Grid}, in Grid
Computing: Making the Global Infrastructure a Reality, Chapter 11, pp. 63???70,
Eds. John Wiley \& Sons Inc., 2002.

\bibitem{cordis:etics}
\emph{E-Infrastructure for Testing, Integration and Configuration of Software
(ETICS)} project, European Community Research and Development Information
Service (CORDIS) [Online]. Available: http://cordis.europa.eu/project/rcn/80138\_en.html

\bibitem{cordis:etics2}
\emph{E-Infrastructure for Testing, Integration and Configuration of Software -
Phase 2 (ETICS 2)} project, European Community Research and Development
Information Service (CORDIS), [Online]. Available: http://cordis.europa.eu/project/rcn/86604\_en.html

\bibitem{etics}
A. Di Meglio, M.-E.B??gin, P. Couvares, E. Ronchieri, E. Takacs, \emph{ETICS:
the international software engineering service for the Grid}, in Journal of
Physics: Conference Series, Vol. 119, N. 4, IOP Publishing Ltd, 2008.

\bibitem{cordis:emi}
\emph{European Middleware Initiative (EMI)} project, European Community
Research and Development Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/95311\_en.html

\bibitem{iso-9126}
\emph{ISO/IEC 9126 Software Engineering - Product Quality}, International
Organization for Standarization [Online]. Available: https://www.iso.org/standard/22749.html

\bibitem{emi-metrics}
\emph{EMI Metrics Specification} [Online]. Available: https://goo.gl/CCtY7x

\bibitem{emi-quality-model}
\emph{EMI Quality Model} [Online]. Available: https://goo.gl/LdS6fL

\bibitem{cordis:egi-inspire}
\emph{European Grid Initiative: Integrated Sustainable Pan-European
Infrastructure for Researchers in Europe (EGI-InSPIRE)} project, European
Community Research and Development Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/95923\_en.html

\bibitem{egi-ops}
\emph{EGI Operations Portal} [Online]. Available:
https://operations-portal.egi.eu/

\bibitem{ggus}
\emph{GGUS} EGI Helpdesk [Online]. Available:
https://ggus.eu/

\bibitem{gocdb}
\emph{GOCDB} EGI Grid Configuration Repository [Online]. Available:
https://ggus.eu/

\bibitem{egi-qc}
\emph{EGI Quality Criteria} [Online]. Available:
https://egi-qc.github.io/

\bibitem{github}
\emph{GITHUB} [Online]. Available:
https://github.com/

\bibitem{jenkins}
\emph{Jenkins} Continuous Integration System [Online]. Available:
https://jenkins-ci.org/

\bibitem{egi-qc}
\emph{EGI Quality Criteria} [Online]. Available: http://egi-qc.github.io/

\bibitem{mario}
M. David et al, \emph{Validation of Grid Middleware for the European Grid
Infrastructure}, in Journal of Grid Computing, vol. 12, issue 3, pp. 543???558,
Springer, 2014.

\bibitem{cordis:egi-engage}
\emph{Engaging the EGI Community towards an Open Science Commons (EGI-ENGAGE)}
project, European Community Research and Development Information Service
(CORDIS), [Online]. Available:  http://cordis.europa.eu/project/rcn/194937\_en.html

\bibitem{cordis:indigo}
\emph{INtegrating Distributed data Infrastructures for Global ExplOitation
(INDIGO--DataCloud)} project, European Community Research and Development
Information Service (CORDIS) [Online]. Available:
http://cordis.europa.eu/project/rcn/194882\_en.html

\bibitem{indigo-dockerhub}
\emph{INDIGO--DataCloud DockerHub repository} [Online]. Available:
https://hub.docker.com/u/indigodatacloud

\bibitem{indigo-d31}
\emph{Initial Plan for WP3} INDIGO--DataCloud Deliverable 3.1 [Online]. Available:
https://www.indigo-datacloud.eu/documents/initial-plan-wp3-d31

\bibitem{indigo-jenkins}
\emph{INDIGO--DataCloud Jenkins CI service} [Online]. Available:
https://jenkins.indigo-datacloud.eu:8080/

\bibitem{indigo-github}
\emph{INDIGO--DataCloud GitHub Source Code repository} [Online]. Available:
https://www.github.com/indigo-dc

\bibitem{indigo-gitbook}
\emph{INDIGO--DataCloud GitBook Documentation repository} [Online]. Available:
https://www.gitbook.com/@indigo-dc

\bibitem{indigo-puppet}
\emph{INDIGO--DataCloud PuppetForge repository} [Online]. Available:
https://forge.puppet.com/indigodc

\bibitem{indigo-galaxy}
\emph{INDIGO--DataCloud Ansible Galaxy repository} [Online]. Available:
https://galaxy.ansible.com/indigo-dc/

\bibitem{indigo-ansible}
\emph{INDIGO--DataCloud Ansible Galaxy repository} [Online]. Available:
https://galaxy.ansible.com/indigo-dc/

\bibitem{grimoirelab}
\emph{GrimoireLab} [Online]. Available: http://grimoirelab.github.io/

\bibitem{indigo-pkg-repo}
\emph{INDIGO--DataCloud Linux Package repository} [Online]. Available: https://jenkins.indigo-datacloud.eu/

\bibitem{ggus}
\emph{Global Grid User Support (GGUS)} [Online]. Available: https://www.ggus.eu/

\bibitem{disvis} G.C.P. Van Zundert, A.M.J.J. Bonvin,
DisVis: quantifying and visualizing the accessible interaction space of distance
restrained biomolecular complexes, Bioinformatics 31 (2015) 3222???3224

\bibitem{powerfit} G.C.P. Van Zundert, A.M.J.J. Bonvin,
Fast and sensitive rigid-body fitting into cryo-EM density maps with PowerFit,
AIMS Biophys. 2 (2015) 73???87.

\end{thebibliography}

\begin{IEEEbiography} [{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/Ronchieri}}]{Elisabetta Ronchieri}
is a Computer Science Engineer at INFN (Istituto Nazionale di Fisica Nucleare - National Institute of Nuclear Physics) CNAF. She holds a PhD in Automation, Robotics and Bioengineering from the University of Pisa. Her main area of interest include software engineering issues, such as software quality and software prediction model. She is also interested in (big and open) data analysis by using techniques coming from various theories, such as Machine Learning.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/pablo-orviz}}]{Pablo Orviz Fernandez}
is a computing researcher at CSIC (Consejo Superior de Investigaciones
Cientificas), holding an MSc in Scientific Computing from the University of
Cantabria. During the past years he has been devoted to software quality
assurance tasks within different European advanced computing research projects
such as INDIGO--DataCloud and EGI-Engage. Currently involved in EOSC-hub project
and participating in the software quality work packages of DEEP-HybridDataCloud
and eXtreme-DataCloud.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/mario-david}}]{Mario David}
is a research associate at LIP. He holds a PhD in Experimental Particle Physics from the University of Lisbon.
Member of DEEP-HybridDataCloud project as Work Package leader of Testbed and integration with EOSC services. Member of EOSC-hub project and
of the Portuguese National Computing Distributed Infrastructure.
He held a research associate position at Institut de Physique du Globe de Paris (IPGP/CNRS) as Scientific Software Developer for the VERCE project, in particular in the data intensive use cases for seismology.
He was been actively involved in the Validation, Quality Assurance and testing of middleware, in regional and global operations.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/cris_foto_good}}]{Doina Cristina Duma}
is the leader of the Distributed Systems group at the INFN National Center (CNAF), providing the core operational support for the INFN-wide Grid infrastructure and for the CNAF Cloud infrastructure. She has a long experience in managing distributed e-infrastructures, being involved since 2003 in major European projects such as DataGrid, EGEE (I, II, III), EGI-Inspire and EGI-Engage. She was the Release Manager of the EMI (European Middleware Initiative) and INDIGO - DataCloud European project project and having as main responsibilities to manage all release activities, including release planning, building, deploying, reporting, establishing and maintaining the overall release timeline and milestones.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/jorge-gomes}}]{Jorge Gomes}
is a computing researcher at LIP. He worked in the development of advanced data acquisition systems at CERN, and participated in pioneering projects in the domain of digital satellite data communications, IP over ATM, and advanced videoconferencing over IP networks. Since 2001 he has participated in numerous projects regarding distributed computing, networks and security in Europe and Latin America. He is the head of the LIP Advanced Computing and Digital Infrastructures Group and technical coordinator of the Portuguese National Grid Infrastructure, representative of Portugal in the Council of the European Grid Infrastructure (EGI) and responsible for the Portuguese participation in IBERGRID, that joins Portuguese and Spanish distributed computing infrastructures.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{images/DavideSalomoni}}]{Davide Salomoni}
is Director of Technology at the Italian National Institute for Nuclear Physics (INFN). He has 27 years of international experience in private and public environments related to distributed computing and communication technologies. He currently leads the Software Development and Distributed Systems department at CNAF, the INFN National Center dedicated to research and development on IT technologies, located in Bologna, Italy. He was Project Coordinator of INDIGO--DataCloud, a project funded by the EC Horizon2020, that developed innovative open source computing and storage solutions.
\end{IEEEbiography}

\end{document}


